{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9657657657657658\n",
      "Recall: 0.6708385481852316\n",
      "F-measure: 0.791728212703102\n",
      "Accuracy: 0.8085539714867617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "#check the performance\n",
    "def checkperformance(result,ActualResult):\n",
    "    truePos=0\n",
    "    trueNeg=0\n",
    "    falsePos=0\n",
    "    falseNeg=0\n",
    "    for i in range(len(result)):\n",
    "        if result[i]==ActualResult[i] and ActualResult[i]==1:\n",
    "            truePos+=1\n",
    "        elif result[i]==ActualResult[i] and ActualResult[i]==0:\n",
    "            trueNeg+=1 \n",
    "        elif result[i]!=ActualResult[i] and ActualResult[i]==1:\n",
    "            falsePos+=1\n",
    "        elif result[i]!=ActualResult[i] and ActualResult[i]==0:\n",
    "            falseNeg+=1 \n",
    "    Precision=truePos/(truePos+falsePos)\n",
    "    Recall=truePos/(truePos+falseNeg)\n",
    "    FMeasure=(2*Precision*Recall)/(Precision+Recall)\n",
    "    Accuracy= (truePos+trueNeg)/(truePos+trueNeg+falseNeg+falsePos)\n",
    "    print(\"Precision:\",Precision)\n",
    "    print(\"Recall:\",Recall)\n",
    "    print(\"F-measure:\",FMeasure)\n",
    "    print(\"Accuracy:\",Accuracy)\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "data = np.genfromtxt('./spambase.data',delimiter=',')\n",
    "#randomise data\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(data)\n",
    "w,h = 1534,57;\n",
    "probs1=[]\n",
    "probs2=[]\n",
    "result=[]\n",
    "\n",
    "\n",
    "#divide data to test , train n class\n",
    "train_pct_index = int((.68) * len(data))\n",
    "train,test = data[:train_pct_index], data[train_pct_index:]\n",
    "spam=[]\n",
    "notspam=[]\n",
    "last = train[:, train.shape[1] - 1:]\n",
    "train = train[:, :train.shape[1] - 1]\n",
    "ActualResult = test[:, test.shape[1] - 1:]\n",
    "test = test[:, :test.shape[1] - 1]\n",
    "\n",
    "#set data to spam and notspam \n",
    "for i in range(len(train)):\n",
    "    if last[i]==1:\n",
    "    \n",
    "        spam.append(train[i])\n",
    "    elif last[i]==0:\n",
    "        notspam.append(train[i])\n",
    "        \n",
    "spam = np.array(spam)  \n",
    "notspam = np.array(notspam)\n",
    "#find prior probability\n",
    "prior_spam=len(spam)/len(train)\n",
    "prior_notspam=len(notspam)/len(train)\n",
    "#find mean and std\n",
    "meanSpam= np.mean(spam, axis=0)\n",
    "meanNonspam= np.mean(notspam, axis=0)\n",
    "stdS = np.std(spam, axis=0)\n",
    "stdNS = np.std(notspam, axis=0)\n",
    "#calculate the probability for test data for spam\n",
    "\n",
    "for i in range(len(test)):\n",
    "    c=1\n",
    "    \n",
    "    for j in range(test.shape[1]):\n",
    "        mid1=((test[i][j]-meanSpam[j])**2)/(2*stdS[j]**2)\n",
    "        mid1=math.exp(-mid1)\n",
    "        mid2=(1 / (stdS[j] * math.sqrt(2 * math.pi)))\n",
    "        p=mid2*mid1\n",
    "        if math.isnan(p)==1:\n",
    "            p=meanSpam[j]\n",
    "#         \n",
    "        c*=p    \n",
    "        \n",
    "    probs1.append(c)\n",
    "np.array(probs1)\n",
    "probs1=np.dot(prior_spam,probs1)\n",
    "#calculate the probability for test data for notspam\n",
    "for i in range(len(test)):\n",
    "    c=1\n",
    "    for j in range(test.shape[1]):\n",
    "        mid1=((test[i][j]-meanNonspam[j])**2)/(2*stdNS[j]**2)\n",
    "        mid1=math.exp(-mid1)\n",
    "        mid2=(1 / (stdNS[j] * math.sqrt(2 * math.pi)))\n",
    "        p=mid2*mid1\n",
    "        if math.isnan(p)==1:\n",
    "            p=meanNonSpam[j]\n",
    "        elif p==0:\n",
    "            p=0.0001\n",
    "        c*=p    \n",
    "        \n",
    "    probs2.append(c)\n",
    "np.array(probs2)\n",
    "probs2=np.dot(prior_notspam,probs2)\n",
    "\n",
    "for i in range(len(test)):\n",
    "    if(probs1[i]>probs2[i]):\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(0)\n",
    "checkperformance(result,ActualResult)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
